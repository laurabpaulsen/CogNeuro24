{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based permutation test\n",
    "\n",
    "The cluster-based permutation test is a non-parametric test to reveal if two conditions are significantly different. I know that this test can be a bit difficult to wrap your head around. Here are some additional resources that I found helpful:\n",
    "\n",
    "- [Intro to cluster permutation statistics](https://benediktehinger.de/blog/science/statistics-cluster-permutation-test/)\n",
    "- [How not to interpret the results](https://www.fieldtriptoolbox.org/faq/how_not_to_interpret_results_from_a_cluster-based_permutation_test/)\n",
    "- [MNE-tutorial](https://mne.tools/stable/auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html#sphx-glr-auto-tutorials-stats-sensor-space-75-cluster-ftest-spatiotemporal-py)\n",
    "- [Fieldtrip tutorial (includes a video)]([https://www.fieldtriptoolbox.org/tutorial/cluster_permutation_timelock/](https://www.fieldtriptoolbox.org/tutorial/cluster_permutation_timelock/))\n",
    "- [The original paper introducing the test](https://pubmed.ncbi.nlm.nih.gov/17517438/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Python\n",
    "First of all, we need to make sure that we are working in the `env` environment.\n",
    "\n",
    "\n",
    "1. Run `bash env_to_ipynb_kernel.sh` from the `EEG` folder if you have not already done so. This will make sure that the `env` environment is available as a kernel in this notebook.\n",
    "\n",
    "2. Press `Select Kernel`, then `Jupyter kernel...` and select `env`. If `env` does not show up, press the little refresh symbol!\n",
    "\n",
    "**Note:** You might have to install the Jupyter extension for VScode to be able to select the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the cluster-based permutation test\n",
    "\n",
    "\n",
    "Shoutout to Mina for the following steps to perform the cluster-based permutation test:\n",
    "1. Set threshold for t-values (contrast) for clustering\n",
    "2. Compare conditions: get t-values for the contrast (for the difference in the two conditions) for each time-stamp\n",
    "3. Form cluster out of t-values for the contrast (two conditions) that go beyond the threshold. Sum the t-values of that particular cluster together with all the neighbouring channels (to get the space dimension). Do this for all the data\n",
    "4. Take the highest t-value sum among all the clusters you identify. Save this number.\n",
    "5. PERMUTATION: Shuffle the two conditions i.e., making an empirical null distribution\n",
    "7. Repeat step 2-4 for the new distribution (data that was shuffled) - recommended to repeat this step 10,000). Save the highest t-value sums of the clusters for each run (i.e., you will end up with 10,000 highest t-value sums)\n",
    "8. Make a distribution of the 10,000 highest t-value sums \n",
    "9. If initial highest t-value value (*from step 4*) is outside the distribution (larger or smaller) then you say that you have a significant difference between the two conditions\n",
    "\n",
    "Luckily, we don't have to do this by hand and we can use one of the `mne-python` functions to do this. However, it is important to understand the steps above to understand the output of the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "First, we load in the data from the three participants and save them in a variable called `all_epochs`, which is a list of `mne.Epochs` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "all_epochs = []\n",
    "\n",
    "data_path = Path(\"/work/EEG_lab/example_data\")\n",
    "\n",
    "for participant in [\"Group1\", \"Group5\", \"Group6\"]:\n",
    "    epochs = mne.read_epochs(data_path / f\"{participant}-epo.fif\", verbose=False, preload=True)\n",
    "\n",
    "    # only keep eeg channels\n",
    "    epochs.pick([\"eeg\"])\n",
    "\n",
    "    all_epochs.append(epochs)\n",
    "\n",
    "\n",
    "print(type(all_epochs)) # we have now created a list of epochs objects\n",
    "print(len(all_epochs)) # we have 3 epochs objects in the list\n",
    "print(type(all_epochs[0])) # we can access the first epochs object in the list which is a Epochs object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the data\n",
    "For the purpose of this example we will be checking if there is a difference between images and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_image = [epochs[\"Image\"] for epochs in all_epochs] # we can use a list comprehension to extract the incorrect trials for each participant\n",
    "epochs_word = [epochs[\"Word\"] for epochs in all_epochs] # we can use a list comprehension to extract the correct trials for each participant\n",
    "\n",
    "# obtain the data as a 3D matrix and transpose it such that\n",
    "# the dimensions are as expected for the cluster permutation test:\n",
    "# n_epochs × n_times × n_channels\n",
    "data_image = [np.transpose(epochs.get_data(copy = True), (0, 2, 1)) for epochs in epochs_image]\n",
    "data_word = [np.transpose(epochs.get_data(copy = True), (0, 2, 1)) for epochs in epochs_word]\n",
    "\n",
    "print(data_image[1].shape) # we can see that the dimensions are now as expected\n",
    "print(data_word[1].shape) # we can see that the dimensions are now as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_subj_image = data_image[0]\n",
    "x_subj_word = data_word[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get adjecency matrix\n",
    "We need to define the adjacency matrix to be able to cluster the data. This is a matrix that defines which channels are neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, ch_type=\"eeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the adjacency\n",
    "mne.viz.plot_ch_adjacency(epochs.info, adjacency, ch_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set family-wise p-value\n",
    "p_accept = 0.05\n",
    "\n",
    "# running the permutation test with 2000 permutations and a random seed of 4\n",
    "cluster_stats = mne.stats.spatio_temporal_cluster_test(\n",
    "    [x_subj_image, x_subj_word],\n",
    "    n_permutations=1000, \n",
    "    tail=0,\n",
    "    n_jobs=-1, \n",
    "    adjacency=adjacency, \n",
    "    seed=4)\n",
    "\n",
    "# selecting clusters with significant p-values\n",
    "F_obs, clusters, p_values, _ = cluster_stats\n",
    "good_cluster_inds = np.where(p_values < p_accept)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# configuration of variables for visualisation\n",
    "colors = {\"Word\": \"forestgreen\", \"Image\": 'steelblue'}\n",
    "\n",
    "# organising data for plotting\n",
    "evokeds = {cond: epochs[cond].average() for cond in ['Word', 'Image']} \n",
    "\n",
    "if len(good_cluster_inds) == 0:\n",
    "    print('No significant clusters found')\n",
    "\n",
    "else:\n",
    "    # looping over clusters\n",
    "    for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "        # unpacking cluster information\n",
    "        time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "        ch_inds = np.unique(space_inds)\n",
    "        time_inds = np.unique(time_inds)\n",
    "\n",
    "        # topography for stats\n",
    "        f_map = F_obs[time_inds, ...].mean(axis=0)\n",
    "\n",
    "        # getting signals at the sensors contributing to the cluster\n",
    "        sig_times = epochs.times[time_inds]\n",
    "\n",
    "        # creating spatial mask\n",
    "        mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n",
    "        mask[ch_inds, :] = True\n",
    "\n",
    "        # initialising the figure\n",
    "        fig, ax_topo = plt.subplots(1, 1, figsize=(12, 4), dpi=300)\n",
    "\n",
    "        # plotting average test statistic and mark significant sensors\n",
    "        image = mne.viz.plot_topomap(\n",
    "            f_map, \n",
    "            evokeds[\"Image\"].info, \n",
    "            axes=ax_topo, \n",
    "            cmap=\"Oranges\", \n",
    "            show=False, \n",
    "            mask=mask\n",
    "            )\n",
    "\n",
    "        # creating additional axes (for ERP and colorbar)\n",
    "        divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "        # adding axes for colourbar\n",
    "        ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        plt.colorbar(image[0], cax=ax_colorbar)\n",
    "        ax_topo.set_xlabel(f\"Averaged F-map ({sig_times[0]:0.3f} - {sig_times[-1]:0.3f} s)\")\n",
    "\n",
    "        # adding new axis for time courses and plot time courses\n",
    "        ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "        title = f'Cluster #{i_clu + 1}, { len(ch_inds)} sensors'\n",
    "        \n",
    "        mne.viz.plot_compare_evokeds(\n",
    "            evokeds, \n",
    "            title=title, \n",
    "            picks=ch_inds, \n",
    "            axes=ax_signals,\n",
    "            colors=colors, \n",
    "            show=False,\n",
    "            combine = \"mean\" # you can also plot GFP if you prefer \n",
    "            )\n",
    "\n",
    "        # plotting temporal cluster extent\n",
    "        ymin, ymax = ax_signals.get_ylim()\n",
    "\n",
    "        # fill between ymin and ymax for all clusters \n",
    "        ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                                color='orange', alpha=0.2)\n",
    "\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group level analysis\n",
    "### Concatenate data from participants\n",
    "We will concatenate the data from the three participants into one numpy array as a preparation for the cluster-based permutation test. Before doing so we will average over trials within each participant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over trials for each participant\n",
    "average_image = [epochs[\"Image\"].get_data().mean(axis=0).transpose() for epochs in all_epochs]\n",
    "average_word = [epochs[\"Word\"].get_data().mean(axis=0).transpose() for epochs in all_epochs]\n",
    "\n",
    "\n",
    "# add a new axis at the beginning of the array\n",
    "average_image = [np.expand_dims(average, axis=0) for average in average_image]\n",
    "average_word = [np.expand_dims(average, axis=0) for average in average_word]\n",
    "\n",
    "X_image_all = np.concatenate(average_image, axis=0)\n",
    "X_word_all = np.concatenate(average_word, axis=0)\n",
    "\n",
    "print(X_image_all.shape) # we can see that the dimensions are now as expected (n_participants × n_channels × n_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the cluster-based permutation test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set family-wise p-value\n",
    "p_accept = 0.05\n",
    "\n",
    "# running the permutation test with 2000 permutations and a random seed of 4\n",
    "cluster_stats = mne.stats.spatio_temporal_cluster_test(\n",
    "    [X_image_all, X_word_all],\n",
    "    n_permutations=1000, \n",
    "    tail=0,\n",
    "    n_jobs=-1, \n",
    "    adjacency=adjacency, \n",
    "    seed=4)\n",
    "\n",
    "# selecting clusters with significant p-values\n",
    "F_obs, clusters, p_values, _ = cluster_stats\n",
    "good_cluster_inds = np.where(p_values < p_accept)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of variables for visualisation\n",
    "colors = {\"Word\": \"forestgreen\", \"Image\": 'steelblue'}\n",
    "\n",
    "# organising data for plotting\n",
    "evokeds = {cond: epochs[cond].average() for cond in ['Word', 'Image']} \n",
    "\n",
    "if len(good_cluster_inds) == 0:\n",
    "    print('No significant clusters found')\n",
    "\n",
    "else:\n",
    "    # looping over clusters\n",
    "    for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "        # unpacking cluster information\n",
    "        time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "        ch_inds = np.unique(space_inds)\n",
    "        time_inds = np.unique(time_inds)\n",
    "\n",
    "        # topography for stats\n",
    "        f_map = F_obs[time_inds, ...].mean(axis=0)\n",
    "\n",
    "        # getting signals at the sensors contributing to the cluster\n",
    "        sig_times = epochs.times[time_inds]\n",
    "\n",
    "        # creating spatial mask\n",
    "        mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n",
    "        mask[ch_inds, :] = True\n",
    "\n",
    "        # initialising the figure\n",
    "        fig, ax_topo = plt.subplots(1, 1, figsize=(12, 4), dpi=300)\n",
    "\n",
    "        # plotting average test statistic and mark significant sensors\n",
    "        image = mne.viz.plot_topomap(\n",
    "            f_map, \n",
    "            evokeds[\"Image\"].info, \n",
    "            axes=ax_topo, \n",
    "            cmap=\"Oranges\", \n",
    "            show=False, \n",
    "            mask=mask\n",
    "            )\n",
    "\n",
    "        # creating additional axes (for ERP and colorbar)\n",
    "        divider = make_axes_locatable(ax_topo)\n",
    "\n",
    "        # adding axes for colourbar\n",
    "        ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        plt.colorbar(image[0], cax=ax_colorbar)\n",
    "        ax_topo.set_xlabel(f\"Averaged F-map ({sig_times[0]:0.3f} - {sig_times[-1]:0.3f} s)\")\n",
    "\n",
    "        # adding new axis for time courses and plot time courses\n",
    "        ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "        title = f'Cluster #{i_clu + 1}, { len(ch_inds)} sensors'\n",
    "        \n",
    "        mne.viz.plot_compare_evokeds(\n",
    "            evokeds, \n",
    "            title=title, \n",
    "            picks=ch_inds, \n",
    "            axes=ax_signals,\n",
    "            colors=colors, \n",
    "            show=False,\n",
    "            combine = \"mean\" # you can also plot GFP if you prefer \n",
    "            )\n",
    "\n",
    "        # plotting temporal cluster extent\n",
    "        ymin, ymax = ax_signals.get_ylim()\n",
    "\n",
    "        # fill between ymin and ymax for all clusters \n",
    "        ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                                color='orange', alpha=0.2)\n",
    "\n",
    "        plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
