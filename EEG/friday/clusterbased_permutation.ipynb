{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based permutation test\n",
    "\n",
    "The cluster-based permutation test is a non-parametric test to reveal if two conditions are significantly different. I know that this test can be a bit difficult to wrap your head around. Here are some additional resources that I found helpful:\n",
    "\n",
    "- [Intro to cluster permutation statistics](https://benediktehinger.de/blog/science/statistics-cluster-permutation-test/)\n",
    "- [How not to interpret the results](https://www.fieldtriptoolbox.org/faq/how_not_to_interpret_results_from_a_cluster-based_permutation_test/)\n",
    "- [MNE-tutorial](https://mne.tools/stable/auto_tutorials/stats-sensor-space/75_cluster_ftest_spatiotemporal.html#sphx-glr-auto-tutorials-stats-sensor-space-75-cluster-ftest-spatiotemporal-py)\n",
    "- [Fieldtrip tutorial (includes a video)]([https://www.fieldtriptoolbox.org/tutorial/cluster_permutation_timelock/](https://www.fieldtriptoolbox.org/tutorial/cluster_permutation_timelock/))\n",
    "- [The original paper introducing the test](https://pubmed.ncbi.nlm.nih.gov/17517438/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the cluster-based permutation test\n",
    "\n",
    "\n",
    "Shoutout to Mina for the following steps to perform the cluster-based permutation test:\n",
    "1. Set threshold for t-values (contrast) for clustering\n",
    "2. Compare conditions: get t-values for the contrast (for the difference in the two conditions) for each time-stamp\n",
    "3. Form cluster out of t-values for the contrast (two conditions) that go beyond the threshold. Sum the t-values of that particular cluster together with all the neighbouring channels (to get the space dimension). Do this for all the data\n",
    "4. Take the highest t-value sum among all the clusters you identify. Save this number.\n",
    "5. PERMUTATION: Shuffle the two conditions i.e., making an empirical null distribution\n",
    "7. Repeat step 2-4 for the new distribution (data that was shuffled) - recommended to repeat this step 10,000). Save the highest t-value sums of the clusters for each run (i.e., you will end up with 10,000 highest t-value sums)\n",
    "8. Make a distribution of the 10,000 highest t-value sums \n",
    "9. If initial highest t-value value (*from step 4*) is outside the distribution (larger or smaller) then you say that you have a significant difference between the two conditions\n",
    "\n",
    "Luckily, we don't have to do this by hand and we can use one of the `mne-python` functions to do this. However, it is important to understand the steps above to understand the output of the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "all_epochs = []\n",
    "# relative path to the data 2 directories up\n",
    "data_path = Path(Path.cwd()).parents[1] / \"data\" / \"preprocessed\"\n",
    "\n",
    "for participant in [\"Group1\", \"Group5\", \"Group6\"]:\n",
    "    epochs = mne.read_epochs(data_path / f\"{participant}-epo.fif\", verbose=False, preload=True)\n",
    "\n",
    "    # only keep eeg channels\n",
    "    epochs.pick_types(eeg=True)\n",
    "\n",
    "    all_epochs.append(epochs)\n",
    "\n",
    "\n",
    "print(type(all_epochs)) # we have now created a list of epochs objects\n",
    "print(len(all_epochs)) # we have 3 epochs objects in the list\n",
    "print(type(all_epochs[0])) # we can access the first epochs object in the list which is a Epochs object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the channel names that are not the same across all participants\n",
    "channel_names = []\n",
    "for epochs in all_epochs:\n",
    "    channel_names.append(epochs.ch_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_names[0])\n",
    "print(channel_names[1])\n",
    "print(channel_names[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this example we will be checking if there is a difference between incorrect and correct button presses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_incorrect = [epochs[\"Incorrect\"] for epochs in all_epochs] # we can use a list comprehension to extract the incorrect trials for each participant\n",
    "epochs_correct = [epochs[\"Correct\"] for epochs in all_epochs] # we can use a list comprehension to extract the correct trials for each participant\n",
    "\n",
    "# obtain the data as a 3D matrix and transpose it such that\n",
    "# the dimensions are as expected for the cluster permutation test:\n",
    "# n_epochs × n_times × n_channels\n",
    "data_incorrect = [np.transpose(epochs.get_data(), (0, 2, 1)) for epochs in epochs_incorrect]\n",
    "data_correct = [np.transpose(epochs.get_data(), (0, 2, 1)) for epochs in epochs_correct]\n",
    "\n",
    "print(data_correct[1].shape) # we can see that the dimensions are now as expected\n",
    "print(data_incorrect[1].shape) # we can see that the dimensions are now as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the adjacency of the sensors\n",
    "adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, ch_type=\"eeg\")\n",
    "\n",
    "# plot the adjacency\n",
    "mne.viz.plot_ch_adjacency(epochs.info, adjacency, ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_incorrect = np.concatenate(data_incorrect, axis=0) # concatenate the data for all participants\n",
    "X_correct = np.concatenate(data_correct, axis=0) # concatenate the data for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_obs, clusters, cluster_p_values, H0 = mne.stats.spatio_temporal_cluster_test(\n",
    "    [X_correct, X_incorrect], # the data for the two conditions\n",
    "    n_permutations=100, # the number of permutations\n",
    "    threshold=dict(start=.5, step=.2), # the threshold for the clusters\n",
    "    n_jobs=1, # we use parallelization\n",
    "    adjacency=adjacency, # the adjacency matrix   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD PLOTTING OF THE CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
