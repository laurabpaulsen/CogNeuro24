{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of EEG data\n",
    "\n",
    "In this notebook, we will go through the basics of preprocessing EEG data using MNE. We will be using some sample data provided with the MNE package to do so. \n",
    "\n",
    "To preprocces the data following steps are performed\n",
    "1. Load the data\n",
    "2. Exclude bad channels\n",
    "3. Common average reference\n",
    "4. Filtering\n",
    "5. Saving the data\n",
    "\n",
    "After preprocessing the data is epoched for further analysis. This is done in the notebook [EEG_analysis.ipynb](EEG_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Python\n",
    "First of all, we need to make sure that we are working in the `env` environment.\n",
    "\n",
    "\n",
    "1. Run `bash env_to_jupyter.sh` from the `EEG` folder if you have not already done so. This will make sure that the `env` environment is available as a kernel in this notebook.\n",
    "\n",
    "2. Press `Select Kernel`, then `Jupyter kernel...` and select `env`. If `env` does not show up, press the little refresh symbol!\n",
    "\n",
    "**Note:** You might have to install the Jupyter extension for VScode to be able to select the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the sample data\n",
    "\n",
    "To begin with we load the MNE sample data. It contains data from an experiment where checkerboard patterns were presented to the subject into the left and right visual (hemi)field, interspersed by tones to the left or right ear. The interval between the stimuli was 750 ms. Occasionally a smiley face was presented at the center of the visual field. The subject was asked to press a key with the right index finger as soon as possible after the appearance of the smiley.\n",
    "\n",
    "Looking at trials across modalities (auditory/visual) we can see the contrast between auditory and visual processing, while inspecting the left/right trials allows us to observe the contralateral visual processing of the brain (i.e. what is presented to the right visual hemifield is processed in the left visual cortex and vice versa).\n",
    "\n",
    "Information about the sample data can be found [here](https://mne.tools/stable/documentation/datasets.html#sample-dataset) (the dataset is called sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file & loading in the data\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n",
    "                                    'sample_audvis_raw.fif')\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file) # raw is an MNE object that contains the data of the class Raw\n",
    "raw.info['bads'] = []\n",
    "\n",
    "raw.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "Looking at the ouput from the load_data() function, answer the following questions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** How many EEG channels are there? **A:**\n",
    "\n",
    "**Q2:** Were any EEG channels marked as bad during recording? **A:**\n",
    "\n",
    "**Q3:** What is the sampling frequency? **A:**\n",
    "\n",
    "**Q4:** How many minutes of data were recorded? **A:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both EEG and MEG (grad and mag) were recorded, but we are only interested in working with the EEG data so we will select only the EEG channels + the stimulus channels which holds the triggers\n",
    "raw.pick(['eeg', 'stim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets try and plot the raw data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we are plotting using the default argument values of the plot() function. Try to play around with `Raw.plot()` method in order to:\n",
    "\n",
    "**1. Plot all EEG channels simultaneously**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot a full minute of the recording**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exclude bad channels\n",
    "When plotting all channels simultaneously, it is evident that one of the channels is not really picking up any signal (that is, it is flat). This is a bad channel and should be excluded from further analysis. There are other ways that channels might be bad, such as being too noisy, or picking up signals from other parts of the body. In this case, we will just exclude the channel that is flat.\n",
    "\n",
    "**Begin by marking the channel as bad using the info attribute of the raw object. Then, plot the data again to see that the channel is now excluded.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info[\"bads\"] = [#insert channel here, #if there was another chacnnel you wanted to remove -insert it here]  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After marking the channel as bad, we need to exclude it from the data. This is done using the pick() method of the raw object.**\n",
    "\n",
    "Hint: set exclude='bads', but remember to keep the stim and the rest of the EEG channels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Common average reference\n",
    "The idea behind common average reference is to compute the average of the signal at all EEG electrodes and subtract it from the EEG signal at every electrode for every time point. To set this “virtual reference” that is the average of all channels, you can use set_eeg_reference() with ref_channels='average'. This is done after excluding bad channels, so the average is computed only over the good channels.\n",
    "\n",
    "The rationale behind this is that the average of all the potentials recorded on the whole head due to current sources inside it is zero, this would make for a quiet or electrically neutral reference. However, in practice, to achieve such an ideal reference one would require large number of electrodes that cover the whole head uniformly, which is not the case in EEG recordings where limited number of electrodes cover mostly the upper part of the head.\n",
    "\n",
    "If you want to know more, this is a good [resource](https://pressrelease.brainproducts.com/referencing/#20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> Note: </b> The data used here has already been referenced to the average of all channels, but this code will be needed when you analyse your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common average reference\n",
    "# raw.set_eeg_reference('average', projection=True)\n",
    "\n",
    "# applying the reference\n",
    "# raw.apply_proj()\n",
    "\n",
    "# plot the data to check that it looks sensical\n",
    "# raw.plot();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering\n",
    "Now let's filter the data. A high-pass filter minimises slow drifts in the data (e.g. scalp potentials), while a low-pass filter excludes high-frequency noise (e.g. line noise (50 Hz) or EMG (muscle-related artefacts), with frequencies higher than the frequencies of the signal we are interested in.\n",
    "\n",
    "\n",
    "**Apply a high-pass filter at 0.1 Hz and a low-pass filter at 40 Hz, following the typical practises of EEG preprocessing.**\n",
    "\n",
    "\n",
    "*Hint: The `Raw` class has a `filter()` method that can be used to filter the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the data to inspect the effect of the filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "**Q5:** If you compare the raw data with the filtered data, what differences do you see? **A:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_path = os.path.join(os.getcwd(), \"preprocessed_data\")\n",
    "\n",
    "# make sure output path exists \n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "# save the data\n",
    "raw.save(os.path.join(output_path, 'preprocessed_data.fif'), overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional exercise: Independent Component Analysis (ICA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<dix class=\"alert alert-block alert-info\">\n",
    "This is an optional exercise. Make sure to go through the EEG analysis notebook before you do this exercise, and then come back to this one if you have time left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ICA can be used for artefact detection, since it identifies seperate components of the signal that have been combined during recording. That means that we can actually separate noise compoenents, such as eye blinks, from the rest of the signal, and thereby exclude them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn # scikit-learn is needed to run ICA (Independent Component Analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some quick preprocessing code of the raw data to get you started. Just run the chunk below and read the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file & loading in the data\n",
    "sample_data_folder = mne.datasets.sample.data_path()\n",
    "sample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample',\n",
    "                                    'sample_audvis_raw.fif')\n",
    "raw = mne.io.read_raw_fif(sample_data_raw_file) # raw is an MNE object that contains the data of the class Raw\n",
    "raw.info['bads'] = []\n",
    "raw.load_data()\n",
    "\n",
    "# pick only EEG\n",
    "raw.pick_types(meg=False, eeg=True, stim=True, exclude=[])\n",
    "\n",
    "# bad channels\n",
    "raw.info['bads'] = ['EEG 053']\n",
    "\n",
    "# common average\n",
    "raw.set_eeg_reference(ref_channels='average', ch_type='eeg')\n",
    "\n",
    "\n",
    "# high-pass \n",
    "# ICA is sensitive to slow drifts, therefore we are here using a high high-pass filter! \n",
    "# Note however, that when applying the ICA, we will do it to data high-pass filtered at 0.1 Hz\n",
    "# See https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA\n",
    "raw_fit = raw.copy().filter(1, None)\n",
    "\n",
    "# low-pass \n",
    "raw_fit = raw_fit.filter(None, 40)\n",
    "\n",
    "# high and low-pass filtering for the data not used to fit the ICA\n",
    "raw = raw.filter(0.1, None)\n",
    "\n",
    "# low-pass \n",
    "raw = raw.filter(None, 40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up and fit ICA with mne.preprocessing.ICA() with 800 iterations with a random seed at 7 (for reproducibility) and n_components=0.95**\n",
    "\n",
    "n_components=0.95 ensures that the number of components selected explain at least 95% of the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the ICA components**\n",
    "\n",
    "*Hint: ica.plot_components*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the time courses of the ICA components**\n",
    "\n",
    "*Hint: ica.plot_sources*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "**Q:** Which components do you suspect to be noise? (*hint: look at the topographies of the components and the time courses of the components*) **A:**\n",
    "\n",
    "**When you have identified them, show them to Laura!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude the eye components and apply ica to the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the data after filtering and using ICA to reject artefacts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "**Q:** Compare your results with and without ICA - can you tell any differences between the two, just qualitatively speaking? **A:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the preprocessed data, so it can be loaded into the EEE_epochs.ipynb notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
